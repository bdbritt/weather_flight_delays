{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bec0275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.core.display import HTML\n",
    "from ipywidgets import Layout\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8db48c",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27670ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data from git\n",
      "Retrieved 840029 records\n"
     ]
    }
   ],
   "source": [
    "print('Retrieving data from git')\n",
    "url = 'https://raw.githubusercontent.com/bdbritt/weather_flight_delays/main/weather_delay_data_cleaned.csv'\n",
    "# df = pd.read_csv('weather_delay_data.csv').sample(frac = 0.30)\n",
    "df = pd.read_csv(url)\n",
    "print(f'Retrieved {df.shape[0]} records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f58a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad times with zeros\n",
    "df['DEP_TIME'] = df['DEP_TIME'].astype(str).str.pad(4, fillchar='0')\n",
    "\n",
    "# add weather even flag\n",
    "df['weather_event'] = np.where(df['WEATHER_DELAY'] != 0, True, False)\n",
    "df['nas_event'] = np.where(df['NAS_DELAY'] != 0, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf8891ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_cols = ['FL_DATE', 'ORIGIN', 'OP_CARRIER', 'DEP_TIME', 'DEP_DELAY', \n",
    "               'WEATHER_DELAY', 'NAS_DELAY','month', 'year',\n",
    "              'travel_season', 'weather_event', 'nas_event']\n",
    "df = df[wanted_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(['DEST', 'OP_CARRIER', 'ARR_TIME', 'ARR_DELAY', 'CRS_ARR_TIME', 'ACTUAL_ELAPSED_TIME'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17c45ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120a74a0",
   "metadata": {},
   "source": [
    "## Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59e1058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_isf_model(X: np.array, outliers_fraction = 'auto') -> IsolationForest: \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    clf = IsolationForest(contamination = outliers_fraction, \n",
    "                          random_state=42, n_jobs=-1).fit(X)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def update_data(df, model, col_index) ->pd.DataFrame:\n",
    "    \n",
    "    df['scores'] = model.decision_function(df.iloc[:, [col_index]].values)\n",
    "    df['anomaly'] = model.predict(df.iloc[:, [col_index]].values)\n",
    "    df['anomaly'] = df['anomaly'].apply(lambda x: True if x ==-1 else False)\n",
    "    \n",
    "    df.shape[0] - df['anomaly'].value_counts()[0]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def get_model_results(df: pd.DataFrame, col_index):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # 2d array of column values\n",
    "    \n",
    "    X = df.iloc[:, [col_index]].values\n",
    "    \n",
    "    model = run_isf_model(X)\n",
    "    \n",
    "    df = update_data(df, model, col_index)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def run_model(df, group_id = ['ORIGIN', 'year'], col_index=8) -> pd.DataFrame:\n",
    "    \n",
    "    df = df.copy()\n",
    "    groups = df.groupby(group_id)\n",
    "    data = pd.concat([get_model_results(v, col_index) for k, v in groups])\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9882802e",
   "metadata": {},
   "source": [
    "## Run IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab9d94b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167557, 14)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_df = df.loc[df['weather_event']==True].copy()\n",
    "# weather_df = weather_df.query('WEATHER_DELAY >= 45')\n",
    "weather_isf_data = run_model(weather_df, col_index=5)\n",
    "weather_isf_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d00a7975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    134132\n",
       "True      33425\n",
       "Name: anomaly, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_isf_data['anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a96d6077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>travel_season</th>\n",
       "      <th>weather_event</th>\n",
       "      <th>nas_event</th>\n",
       "      <th>scores</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84849</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>ATL</td>\n",
       "      <td>WN</td>\n",
       "      <td>1723</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85180</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DL</td>\n",
       "      <td>2256</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.014018</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85181</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DL</td>\n",
       "      <td>1955</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.014018</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85182</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DL</td>\n",
       "      <td>1802</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.071311</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85183</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DL</td>\n",
       "      <td>1812</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.078049</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FL_DATE ORIGIN OP_CARRIER DEP_TIME  DEP_DELAY  WEATHER_DELAY  \\\n",
       "84849  2014-01-01    ATL         WN     1723       63.0           63.0   \n",
       "85180  2014-01-02    ATL         DL     2256       55.0            1.0   \n",
       "85181  2014-01-02    ATL         DL     1955       23.0            1.0   \n",
       "85182  2014-01-02    ATL         DL     1802       26.0           26.0   \n",
       "85183  2014-01-02    ATL         DL     1812       37.0            6.0   \n",
       "\n",
       "       NAS_DELAY  month  year travel_season  weather_event  nas_event  \\\n",
       "84849       35.0      1  2014           low           True       True   \n",
       "85180        0.0      1  2014           low           True      False   \n",
       "85181        0.0      1  2014           low           True      False   \n",
       "85182        5.0      1  2014           low           True       True   \n",
       "85183        0.0      1  2014           low           True      False   \n",
       "\n",
       "         scores  anomaly  \n",
       "84849 -0.006616     True  \n",
       "85180 -0.014018     True  \n",
       "85181 -0.014018     True  \n",
       "85182  0.071311    False  \n",
       "85183  0.078049    False  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_isf_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e831660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isf_data.groupby(['ORIGIN', 'year', 'travel_season'])['WEATHER_DELAY'].describe().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65678a2",
   "metadata": {},
   "source": [
    "## Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88d2f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = weather_isf_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f20052fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from scipy import stats\n",
    "from statsmodels.robust.scale import mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "00d4f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL = 'ALL'\n",
    "def unique_sorted_values_plus_ALL(array):\n",
    "    unique = array.unique().tolist()\n",
    "    unique.sort()\n",
    "    unique.insert(0, ALL)\n",
    "    return unique\n",
    "\n",
    "def get_describe(df):\n",
    "    df = df.copy()\n",
    "    df = df.loc[df['anomaly']==True]\n",
    "    df = df.groupby(['year', 'travel_season'])['WEATHER_DELAY'].describe().reset_index()\n",
    "    display(df)\n",
    "\n",
    "def get_bar_graph(df):\n",
    "    origin = df['ORIGIN'].unique()[0]\n",
    "    df = df.copy()\n",
    "    df = df.loc[df['anomaly']==True]\n",
    "    \n",
    "    df = df.groupby(['year', 'travel_season']).agg({'WEATHER_DELAY':'sum'}).reset_index()\n",
    "    \n",
    "    fig = px.bar(df, color='travel_season', y='WEATHER_DELAY', x='year', barmode='group', title=f'{origin} Total Season by Year')\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def determine_est_of_location(df, col1):\n",
    "    \"\"\"\n",
    "    Prints common estimate of location \n",
    "    information for data\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.loc[df['anomaly']==True]\n",
    "    print(f'\\nMax: {df[col1].describe()[7]}')\n",
    "    print(f'Min: {df[col1].describe()[3]}')\n",
    "    print(f'Mean: {round(np.mean(df[col1]),2)}')\n",
    "    print(f'Trimmed Mean: {round(stats.trim_mean(df[col1], proportiontocut=0.1),2)}')\n",
    "    print(f'Median: {df[col1].median()}')\n",
    "\n",
    "\n",
    "def determine_est_of_variability(df, col1):\n",
    "    \"\"\"\n",
    "    Prints common estimate of variability \n",
    "    information for data\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.loc[df['anomaly']==True]\n",
    "    print(f'\\nSTD: {round(np.std(df[col1]),2)}') # population STD\n",
    "    temp = df.describe(include=[np.number],percentiles=[.10,.90]).T\n",
    "    tstd = stats.tstd(df[col1],(temp['10%'].tolist()[0],temp['90%'].tolist()[0]))\n",
    "    print(f'Trimmed STD: {round(tstd,2)}')\n",
    "    print(f'IQR: {df[col1].quantile(0.75) - df[col1].quantile(0.25)}')\n",
    "    print(f'Mean absolute deviation: {round(df[col1].mad(),2)}')\n",
    "    print(f'Median absolute deviation: {round(mad(df[col1]),2)}')\n",
    "\n",
    "\n",
    "def get_histogram(df):\n",
    "    origin = df['ORIGIN'].unique()[0]\n",
    "    df = df.copy()\n",
    "    df = df.loc[df['anomaly']==True]\n",
    "    \n",
    "    fig = px.box(df, x=\"year\", y=\"WEATHER_DELAY\", color=\"travel_season\")\n",
    "    fig.show()\n",
    "    \n",
    "def get_line_graph(df):\n",
    "    \n",
    "    non_anomalies_monthly_sum = df.loc[df['anomaly']==False].groupby(['year', 'month'])['WEATHER_DELAY'].sum().to_frame('total_min').reset_index()\n",
    "    anomalies_monthly_sum = df.loc[df['anomaly']==True].groupby(['year', 'month'])['WEATHER_DELAY'].sum().to_frame('total_min').reset_index()\n",
    "    \n",
    "    non_anomalies_monthly_sum['anomaly'] = False\n",
    "    anomalies_monthly_sum['anomaly'] = True\n",
    "    data_sum = pd.concat([non_anomalies_monthly_sum, anomalies_monthly_sum])\n",
    "    \n",
    "    fig = go.Figure()\n",
    " \n",
    "    chart_name = 'test'\n",
    "    \n",
    "    # 2014\n",
    "    non_2014 = non_anomalies_monthly_sum.loc[non_anomalies_monthly_sum['year']==2014].copy()\n",
    "    ano_2014 = anomalies_monthly_sum.loc[anomalies_monthly_sum['year']==2014].copy()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=non_2014['month'], y=non_2014['total_min'], name='2014-Non',\n",
    "                         line=dict(color='red', width=2)))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=ano_2014['month'], y=ano_2014['total_min'], name='2014-Anomalies',\n",
    "                         line=dict(color='red', width=2,\n",
    "                              dash='dash')))\n",
    "    \n",
    "    # 2015\n",
    "    non_2015 = non_anomalies_monthly_sum.loc[non_anomalies_monthly_sum['year']==2015].copy()\n",
    "    ano_2015 = anomalies_monthly_sum.loc[anomalies_monthly_sum['year']==2015].copy()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=non_2015['month'], y=non_2015['total_min'], name='2015-Non',\n",
    "                         line=dict(color='green', width=2)))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=ano_2015['month'], y=ano_2015['total_min'], name='2015-Anomalies',\n",
    "                         line=dict(color='green', width=2,\n",
    "                              dash='dash')))\n",
    "    \n",
    "    \n",
    "    # 2016\n",
    "    non_2016 = non_anomalies_monthly_sum.loc[non_anomalies_monthly_sum['year']==2016].copy()\n",
    "    ano_2016 = anomalies_monthly_sum.loc[anomalies_monthly_sum['year']==2016].copy()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=non_2016['month'], y=non_2016['total_min'], name='2016-Non',\n",
    "                         line=dict(color='blue', width=2)))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=ano_2016['month'], y=ano_2016['total_min'], name='2016-Anomalies',\n",
    "                         line=dict(color='blue', width=2,\n",
    "                              dash='dash')))\n",
    "    \n",
    "    \n",
    "    # 2017\n",
    "    non_2017 = non_anomalies_monthly_sum.loc[non_anomalies_monthly_sum['year']==2017].copy()\n",
    "    ano_2017 = anomalies_monthly_sum.loc[anomalies_monthly_sum['year']==2017].copy()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=non_2017['month'], y=non_2017['total_min'], name='2017-Non',\n",
    "                         line=dict(color='goldenrod', width=2)))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=ano_2017['month'], y=ano_2017['total_min'], name='2017-Anomalies',\n",
    "                         line=dict(color='goldenrod', width=2,\n",
    "                              dash='dash')))\n",
    "    \n",
    "    \n",
    "    # 2018\n",
    "    non_2018 = non_anomalies_monthly_sum.loc[non_anomalies_monthly_sum['year']==2018].copy()\n",
    "    ano_2018 = anomalies_monthly_sum.loc[anomalies_monthly_sum['year']==2018].copy()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=non_2018['month'], y=non_2018['total_min'], name='2018-Non',\n",
    "                         line=dict(color='magenta', width=2)))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=ano_2018['month'], y=ano_2018['total_min'], name='2018-Anomalies',\n",
    "                         line=dict(color='magenta', width=2,\n",
    "                              dash='dash')))\n",
    "    \n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "53006c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdown_state = widgets.Dropdown(options = unique_sorted_values_plus_ALL(data.ORIGIN), description='Origin: ')\n",
    "\n",
    "output_origin = widgets.Output()\n",
    "describe_output = widgets.Output()\n",
    "bar_graph_output = widgets.Output()\n",
    "histo_graph_output = widgets.Output()\n",
    "line_graph_output = widgets.Output()\n",
    "\n",
    "def event_action():\n",
    "    # clear the previous selection on each iteration\n",
    "    output_origin.clear_output()\n",
    "    describe_output.clear_output()\n",
    "    bar_graph_output.clear_output()\n",
    "    histo_graph_output.clear_output()\n",
    "    line_graph_output.clear_output()\n",
    "    \n",
    "    if (dropdown_state.value == ALL):\n",
    "        common_filter = data\n",
    "        \n",
    "    else:\n",
    "        common_filter = data[data.ORIGIN == dropdown_state.value]\n",
    "    \n",
    "    with output_origin:\n",
    "        print(f'Anamoly Record count: {common_filter.shape[0]}')\n",
    "        determine_est_of_location(common_filter, 'WEATHER_DELAY')\n",
    "        determine_est_of_variability(common_filter, 'WEATHER_DELAY')\n",
    "        \n",
    "        print('\\nDelays 45 min >=')\n",
    "        \n",
    "        query_syn = 'WEATHER_DELAY >= 45'\n",
    "        filter_45min = common_filter.query(query_syn)\n",
    "        print(f'Record count: {filter_45min.shape[0]}')\n",
    "        determine_est_of_location(filter_45min, 'WEATHER_DELAY')\n",
    "        determine_est_of_variability(filter_45min, 'WEATHER_DELAY')\n",
    "    \n",
    "    with describe_output:\n",
    "        get_describe(common_filter)\n",
    "    \n",
    "    with bar_graph_output:\n",
    "        get_bar_graph(common_filter)\n",
    "    \n",
    "    with histo_graph_output:\n",
    "        get_histogram(common_filter)\n",
    "    \n",
    "    with line_graph_output:\n",
    "        get_line_graph(common_filter)\n",
    "        \n",
    "        \n",
    "\n",
    "def dropdown_state_eventhandler(change):\n",
    "    event_action()\n",
    "    \n",
    "def graphit():\n",
    "    event_action()\n",
    "    \n",
    "def tab_chg(chg):\n",
    "    if chg.old == {}:\n",
    "        graphit()\n",
    "\n",
    "dropdown_state.observe(dropdown_state_eventhandler, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "575a1d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf0e49bee474f60afb3544f50ed81ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Origin: ', index=2, options=('ALL', 'ATL', 'DEN', 'DFW', 'LAX', 'ORD'), v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f37f5f7c72a4c419b6b1fe97a43ccc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Output(outputs=({'output_type': 'stream', 'text': 'Anamoly Record count: 19579\\n\\…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_widgets = widgets.HBox([dropdown_state])\n",
    "\n",
    "tab = widgets.Tab([output_origin, describe_output, bar_graph_output, histo_graph_output, line_graph_output])\n",
    "tab.set_title(0, 'Dataset')\n",
    "tab.set_title(1, 'Describe Data')\n",
    "tab.set_title(2, 'Travel Season By Year')\n",
    "tab.set_title(3, 'Distribution')\n",
    "tab.set_title(4, 'Line Chart')\n",
    "# tab.set_title(5, 'State Density Plot')\n",
    "tab.observe(tab_chg)\n",
    "\n",
    "dashboard = widgets.VBox([tab], layout=Layout(height='700px'))\n",
    "display(input_widgets, dashboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f3175",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9c8161f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "testing = data.loc[data['ORIGIN']=='ATL'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "eba46c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a2a0e2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9721, 14)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing2 = testing.loc[testing['anomaly']==True].copy()\n",
    "testing2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8a1cdd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>OP_CARRIER</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>DEP_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "      <th>NAS_DELAY</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>travel_season</th>\n",
       "      <th>weather_event</th>\n",
       "      <th>nas_event</th>\n",
       "      <th>scores</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84849</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>ATL</td>\n",
       "      <td>WN</td>\n",
       "      <td>1723</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85180</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DL</td>\n",
       "      <td>2256</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.014018</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85181</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DL</td>\n",
       "      <td>1955</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.014018</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85191</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DL</td>\n",
       "      <td>1955</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.014018</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85194</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>ATL</td>\n",
       "      <td>DL</td>\n",
       "      <td>2120</td>\n",
       "      <td>85.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.028418</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          FL_DATE ORIGIN OP_CARRIER DEP_TIME  DEP_DELAY  WEATHER_DELAY  \\\n",
       "84849  2014-01-01    ATL         WN     1723       63.0           63.0   \n",
       "85180  2014-01-02    ATL         DL     2256       55.0            1.0   \n",
       "85181  2014-01-02    ATL         DL     1955       23.0            1.0   \n",
       "85191  2014-01-02    ATL         DL     1955       51.0            1.0   \n",
       "85194  2014-01-02    ATL         DL     2120       85.0           81.0   \n",
       "\n",
       "       NAS_DELAY  month  year travel_season  weather_event  nas_event  \\\n",
       "84849       35.0      1  2014           low           True       True   \n",
       "85180        0.0      1  2014           low           True      False   \n",
       "85181        0.0      1  2014           low           True      False   \n",
       "85191        0.0      1  2014           low           True      False   \n",
       "85194        0.0      1  2014           low           True      False   \n",
       "\n",
       "         scores  anomaly  \n",
       "84849 -0.006616     True  \n",
       "85180 -0.014018     True  \n",
       "85181 -0.014018     True  \n",
       "85191 -0.014018     True  \n",
       "85194 -0.028418     True  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9246071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# Generate train data\n",
    "X = 0.3 * rng.randn(100, 2)\n",
    "X_train = np.r_[X + 2, X - 2]\n",
    "# Generate some regular novel observations\n",
    "X = 0.3 * rng.randn(20, 2)\n",
    "X_test = np.r_[X + 2, X - 2]\n",
    "# Generate some abnormal novel observations\n",
    "X_outliers = rng.uniform(low=-4, high=4, size=(20, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0cb903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "clf = IsolationForest(max_samples=100, random_state=rng)\n",
    "clf.fit(X_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_pred_outliers = clf.predict(X_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b445e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the line, the samples, and the nearest vectors to the plane\n",
    "xx, yy = np.meshgrid(np.linspace(-5, 5, 50), np.linspace(-5, 5, 50))\n",
    "Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbdd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"IsolationForest\")\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Blues_r)\n",
    "\n",
    "b1 = plt.scatter(X_train[:, 0], X_train[:, 1], c=\"white\", s=20, edgecolor=\"k\")\n",
    "b2 = plt.scatter(X_test[:, 0], X_test[:, 1], c=\"green\", s=20, edgecolor=\"k\")\n",
    "c = plt.scatter(X_outliers[:, 0], X_outliers[:, 1], c=\"red\", s=20, edgecolor=\"k\")\n",
    "plt.axis(\"tight\")\n",
    "plt.xlim((-5, 5))\n",
    "plt.ylim((-5, 5))\n",
    "plt.legend(\n",
    "    [b1, b2, c],\n",
    "    [\"training observations\", \"new regular observations\", \"new abnormal observations\"],\n",
    "    loc=\"upper left\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226cdd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_testing(X, X_outliers):\n",
    "    \n",
    "    X_train, X_test = train_test_split(X,test_size = 0.20, random_state=42)\n",
    "    \n",
    "    # fit the model\n",
    "    clf = IsolationForest(max_samples=100, random_state=rng)\n",
    "    clf.fit(X_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    y_pred_outliers = clf.predict(X_outliers)\n",
    "    \n",
    "    plt.title(\"IsolationForest\")\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.Blues_r)\n",
    "    \n",
    "#     plt.figure(figsize=(8, 8), dpi=80)\n",
    "\n",
    "    b1 = plt.scatter(X_train[:, 0], X_train[:, 1], c=\"white\", s=20, edgecolor=\"k\")\n",
    "    b2 = plt.scatter(X_test[:, 0], X_test[:, 1], c=\"green\", s=20, edgecolor=\"k\")\n",
    "    c = plt.scatter(X_outliers[:, 0], X_outliers[:, 1], c=\"red\", s=20, edgecolor=\"k\")\n",
    "    plt.axis(\"tight\")\n",
    "#     plt.xlim((-5, 5))\n",
    "#     plt.ylim((-5, 5))\n",
    "    plt.legend(\n",
    "        [b1, b2, c],\n",
    "        [\"training observations\", \"new regular observations\", \"new abnormal observations\"],\n",
    "        loc=\"upper left\",\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e806ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df_testing.loc[df_testing['year'] != 2018].copy(deep=True)\n",
    "df_pred = df_testing.loc[df_testing['year'] == 2018].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00390827",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_testing(df_training.iloc[:, [8,9]].values, df_pred.iloc[:, [8,9]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7775f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8243a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = org_test.iloc[:, [8]].values\n",
    "X1 = org_test.iloc[:, [9]].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
